{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('google_evandro.json')\n",
    "df.replace(r'\\n', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Contributor</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google AI Blog: Permutation-Invariant Neural N...</td>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>[David Ha, Yujin Tang]</td>\n",
       "      <td>Posted by David Ha, Staff Research Scientist a...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/permutation-...</td>\n",
       "      <td>[Staff Research Scientist, Research Software E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google AI Blog: Making Better Future Predictio...</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>[Dave Epstein, Chen Sun]</td>\n",
       "      <td>Posted by Dave Epstein, Student Researcher and...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/making-bette...</td>\n",
       "      <td>[Student Researcher, Staff Research Scientist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google AI Blog: An Open Source Vibrotactile Ha...</td>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>[Artem Dementyev]</td>\n",
       "      <td>Posted by Artem Dementyev, Hardware Engineer, ...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/an-open-sour...</td>\n",
       "      <td>[Hardware Engineer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google AI Blog: MetNet-2: Deep Learning for 12...</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>[Nal Kalchbrenner, Lasse Espeholt]</td>\n",
       "      <td>Posted by Nal Kalchbrenner and Lasse Espeholt,...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/metnet-2-dee...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google AI Blog: RLiable: Towards Reliable Eval...</td>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>[Rishabh Agarwal, Pablo Samuel Castro]</td>\n",
       "      <td>Posted by Rishabh Agarwal, Research Scientist ...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/rliable-towa...</td>\n",
       "      <td>[Research Scientist, Staff Software Engineer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Google AI Blog: First Robots</td>\n",
       "      <td>2006-03-22</td>\n",
       "      <td>[Sumit Agarwal, &amp; Michael Stoppelman]</td>\n",
       "      <td>Posted by  Sumit Agarwal, Maryam Kamvar, &amp; Mic...</td>\n",
       "      <td>https://ai.googleblog.com/2006/03/first-robots...</td>\n",
       "      <td>[Maryam Kamvar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Google AI Blog: See you at CHI</td>\n",
       "      <td>2006-04-23</td>\n",
       "      <td>[Rick Boardman]</td>\n",
       "      <td>Posted by Rick Boardman, User Experience Resea...</td>\n",
       "      <td>https://ai.googleblog.com/2006/04/see-you-at-c...</td>\n",
       "      <td>[User Experience Researcher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Google AI Blog: Our conference on automated te...</td>\n",
       "      <td>2006-04-27</td>\n",
       "      <td>[Allen Hutchison]</td>\n",
       "      <td>Posted by Allen Hutchison, Engineering Manager...</td>\n",
       "      <td>https://ai.googleblog.com/2006/04/our-conferen...</td>\n",
       "      <td>[Engineering Manager]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Google AI Blog: Statistical machine translatio...</td>\n",
       "      <td>2006-04-28</td>\n",
       "      <td>[Franz Och]</td>\n",
       "      <td>Posted by Franz Och, Research ScientistBecause...</td>\n",
       "      <td>https://ai.googleblog.com/2006/04/statistical-...</td>\n",
       "      <td>[Research Scientist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Google AI Blog: Extra, Extra - Read All About ...</td>\n",
       "      <td>2006-06-02</td>\n",
       "      <td>[Joshua Bloch]</td>\n",
       "      <td>Posted by Joshua Bloch, Software EngineerI rem...</td>\n",
       "      <td>https://ai.googleblog.com/2006/06/extra-extra-...</td>\n",
       "      <td>[Software Engineer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title       Date  \\\n",
       "0     Google AI Blog: Permutation-Invariant Neural N... 2021-11-18   \n",
       "1     Google AI Blog: Making Better Future Predictio... 2021-11-11   \n",
       "2     Google AI Blog: An Open Source Vibrotactile Ha... 2021-11-12   \n",
       "3     Google AI Blog: MetNet-2: Deep Learning for 12... 2021-11-15   \n",
       "4     Google AI Blog: RLiable: Towards Reliable Eval... 2021-11-17   \n",
       "...                                                 ...        ...   \n",
       "1004                       Google AI Blog: First Robots 2006-03-22   \n",
       "1005                     Google AI Blog: See you at CHI 2006-04-23   \n",
       "1006  Google AI Blog: Our conference on automated te... 2006-04-27   \n",
       "1007  Google AI Blog: Statistical machine translatio... 2006-04-28   \n",
       "1008  Google AI Blog: Extra, Extra - Read All About ... 2006-06-02   \n",
       "\n",
       "                                 Contributor  \\\n",
       "0                     [David Ha, Yujin Tang]   \n",
       "1                   [Dave Epstein, Chen Sun]   \n",
       "2                          [Artem Dementyev]   \n",
       "3         [Nal Kalchbrenner, Lasse Espeholt]   \n",
       "4     [Rishabh Agarwal, Pablo Samuel Castro]   \n",
       "...                                      ...   \n",
       "1004   [Sumit Agarwal, & Michael Stoppelman]   \n",
       "1005                         [Rick Boardman]   \n",
       "1006                       [Allen Hutchison]   \n",
       "1007                             [Franz Och]   \n",
       "1008                          [Joshua Bloch]   \n",
       "\n",
       "                                                Content  \\\n",
       "0     Posted by David Ha, Staff Research Scientist a...   \n",
       "1     Posted by Dave Epstein, Student Researcher and...   \n",
       "2     Posted by Artem Dementyev, Hardware Engineer, ...   \n",
       "3     Posted by Nal Kalchbrenner and Lasse Espeholt,...   \n",
       "4     Posted by Rishabh Agarwal, Research Scientist ...   \n",
       "...                                                 ...   \n",
       "1004  Posted by  Sumit Agarwal, Maryam Kamvar, & Mic...   \n",
       "1005  Posted by Rick Boardman, User Experience Resea...   \n",
       "1006  Posted by Allen Hutchison, Engineering Manager...   \n",
       "1007  Posted by Franz Och, Research ScientistBecause...   \n",
       "1008  Posted by Joshua Bloch, Software EngineerI rem...   \n",
       "\n",
       "                                                   Link  \\\n",
       "0     https://ai.googleblog.com/2021/11/permutation-...   \n",
       "1     https://ai.googleblog.com/2021/11/making-bette...   \n",
       "2     https://ai.googleblog.com/2021/11/an-open-sour...   \n",
       "3     https://ai.googleblog.com/2021/11/metnet-2-dee...   \n",
       "4     https://ai.googleblog.com/2021/11/rliable-towa...   \n",
       "...                                                 ...   \n",
       "1004  https://ai.googleblog.com/2006/03/first-robots...   \n",
       "1005  https://ai.googleblog.com/2006/04/see-you-at-c...   \n",
       "1006  https://ai.googleblog.com/2006/04/our-conferen...   \n",
       "1007  https://ai.googleblog.com/2006/04/statistical-...   \n",
       "1008  https://ai.googleblog.com/2006/06/extra-extra-...   \n",
       "\n",
       "                                                   Role  \n",
       "0     [Staff Research Scientist, Research Software E...  \n",
       "1        [Student Researcher, Staff Research Scientist]  \n",
       "2                                   [Hardware Engineer]  \n",
       "3                                                        \n",
       "4         [Research Scientist, Staff Software Engineer]  \n",
       "...                                                 ...  \n",
       "1004                                    [Maryam Kamvar]  \n",
       "1005                       [User Experience Researcher]  \n",
       "1006                              [Engineering Manager]  \n",
       "1007                               [Research Scientist]  \n",
       "1008                                [Software Engineer]  \n",
       "\n",
       "[1009 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title          0\n",
       "Date           0\n",
       "Contributor    0\n",
       "Content        0\n",
       "Link           0\n",
       "Role           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.015, 'neu': 0.924, 'pos': 0.061, 'compound': 0.9969}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df.iloc[0]['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Posted by David Ha, Staff Research Scientist and Yujin Tang, Research Software Engineer, Google Research, Tokyo“The brain is able to use information coming from the skin as if it were coming from the eyes. We don’t see with the eyes or hear with the ears, these are just the receptors, seeing and hearing in fact goes on in the brain.”— Paul Bach-y-Rita1People have the amazing ability to use one sensory modality (e.g., touch) to supply environmental information normally gathered by another sense (e.g., vision). This adaptive ability, called sensory substitution, is a phenomenon well-known to neuroscience. While difficult adaptations — such as adjusting to seeing things upside-down, learning to ride a “backwards” bicycle, or learning to “see” by interpreting visual information emitted from a grid of electrodes placed on one’s tongue — require anywhere from weeks, months or even years to attain mastery, people are able to eventually adjust to sensory substitutions.Examples of Sensory Substitution. Left: Tongue Display Unit (Maris and Bach-y-Rita, 2001; Image: Kaczmarek, 2011). Right: “Upside down goggles” initially conceived by Erismann and Kohler in 1931. (Image Wikipedia).In contrast, most neural networks are not able to adapt to sensory substitutions at all. For instance, most reinforcement learning (RL) agents require their inputs to be in a pre-specified format, or else they will fail. They expect fixed-size inputs and assume that each element of the input carries a precise meaning, such as the pixel intensity at a specified location, or state information, like position or velocity. In popular RL benchmark tasks (e.g., Ant or Cart-pole), an agent trained using current RL algorithms will fail if its sensory inputs are changed or if the agent is fed additional noisy inputs that are unrelated to the task at hand. In “The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning”, a spotlight paper at NeurIPS 2021, we explore permutation invariant neural network agents, which require each of their sensory neurons (receptors that receive sensory inputs from the environment) to figure out the meaning and context of its input signal, rather than explicitly assuming a fixed meaning. Our experiments show that such agents are robust to observations that contain additional redundant or noisy information, and to observations that are corrupt and incomplete. Permutation invariant reinforcement learning agents adapting to sensory substitutions. Left: The ordering of the ant’s 28 observations are randomly shuffled every 200 time-steps. Unlike the standard policy, our policy is not affected by the suddenly permuted inputs. Right: Cart-pole agent given many redundant noisy inputs (Interactive web-demo).In addition to adapting to sensory substitutions in state-observation environments (like the ant and cart-pole examples), we show that these agents can also adapt to sensory substitutions in complex visual-observation environments (such as a CarRacing game that uses only pixel observations) and can perform when the stream of input images is constantly being reshuffled:We partition the visual input from CarRacing into a 2D grid of small patches, and shuffled their ordering. Without any additional training, our agent still performs even when the original training background (left) is replaced with new images (right).MethodOur approach takes observations from the environment at each time-step and feeds each element of the observation into distinct, but identical neural networks (called “sensory neurons”), each with no fixed relationship with one another. Each sensory neuron integrates over time information from only their particular sensory input channel. Because each sensory neuron receives only a small part of the full picture, they need to self-organize through communication in order for a global coherent behavior to emerge.Illustration of observation segmentation.We segment each input into elements, which are then fed to independent sensory neurons. For non-vision tasks where the inputs are usually 1D vectors, each element is a scalar. For vision tasks, we crop each input image into non-overlapping patches.We encourage neurons to communicate with each other by training them to broadcast messages. While receiving information locally, each individual sensory neuron also continually broadcasts an output message at each time-step. These messages are consolidated and combined into an output vector, called the global latent code, using an attention mechanism similar to that applied in the Transformer architecture. A policy network then uses the global latent code to produce the action that the agent will use to interact with the environment. This action is also fed back into each sensory neuron in the next time-step, closing the communication loop.Overview of the permutation-invariant RL method. We first feed each individual observation (ot) into a particular sensory neuron (along with the agent’s previous action, at-1). Each neuron then produces and broadcasts a message independently, and an attention mechanism summarizes them into a global latent code (mt) that is given to the agent's downstream policy network (𝜋) to produce the agent’s action at.Why is this system permutation invariant? Each sensory neuron is an identical neural network that is not confined to only process information from one particular sensory input. In fact, in our setup, the inputs to each sensory neuron are not defined. Instead, each neuron must figure out the meaning of its input signal by paying attention to the inputs received by the other sensory neurons, rather than explicitly assuming a fixed meaning. This encourages the agent to process the entire input as an unordered set, making the system to be permutation invariant to its input. Furthermore, in principle, the agent can use as many sensory neurons as required, thus enabling it to process observations of arbitrary length. Both of these properties will help the agent adapt to sensory substitutions.ResultsWe demonstrate the robustness and flexibility of this approach in simpler, state-observation environments, where the observations the agent receives as inputs are low-dimensional vectors holding information about the agent’s states, such as the position or velocity of its components. The agent in the popular Ant locomotion task has a total of 28 inputs with information that includes positions and velocities. We shuffle the order of the input vector several times during a trial and show that the agent is rapidly able to adapt and is still able to walk forward.In cart-pole, the agent’s goal is to swing up a cart-pole mounted at the center of the cart and balance it upright. Normally the agent sees only five inputs, but we modify the cartpole environment to provide 15 shuffled input signals, 10 of which are pure noise, and the remainder of which are the actual observations from the environment. The agent is still able to perform the task, demonstrating the system’s capacity to work with a large number of inputs and attend only to channels it deems useful. Such flexibility may find useful applications for processing a large unspecified number of signals, most of which are noise, from ill-defined systems.We also apply this approach to high-dimensional vision-based environments where the observation is a stream of pixel images. Here, we investigate screen-shuffled versions of vision-based RL environments, where each observation frame is divided into a grid of patches, and like a puzzle, the agent must process the patches in a shuffled order to determine a course of action to take. To demonstrate our approach on vision-based tasks, we created a shuffled version of Atari Pong.Shuffled Pong results. Left: Pong agent trained to play using only 30% of the patches matches performance of Atari opponent. Right: Without extra training, when we give the agent more puzzle pieces, its performance increases.Here the agent’s input is a variable-length list of patches, so unlike typical RL agents, the agent only gets to “see” a subset of patches from the screen. In the puzzle pong experiment, we pass to the agent a random sample of patches across the screen, which are then fixed through the remainder of the game. We find that we can discard 70% of the patches (at these fixed-random locations) and still train the agent to perform well against the built-in Atari opponent. Interestingly, if we then reveal additional information to the agent (e.g., allowing it access to more image patches), its performance increases, even without additional training. When the agent receives all the patches, in shuffled order, it wins 100% of the time, achieving the same result with agents that are trained while seeing the entire screen.We find that imposing additional difficulty during training by using unordered observations has additional benefits, such as improving generalization to unseen variations of the task, like when the background of the CarRacing training environment is replaced with a novel image.Shuffled CarRacing results. The agent has learned to focus its attention (indicated by the highlighted patches) on the road boundaries. Left: Training environment. Right: Test environment with new background.ConclusionThe permutation invariant neural network agents presented here can handle ill-defined, varying observation spaces. Our agents are robust to observations that contain redundant or noisy information, or observations that are corrupt and incomplete. We believe that permutation invariant systems open up numerous possibilities in reinforcement learning.If you’re interested to learn more about this work, we invite readers to read our interactive article (pdf version) or watch our video. We also released code to reproduce our experiments.1Quoted in Livewired, by David Eagleman. \\xa0↩\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scores'] = df['Content'].apply(lambda content: sid.polarity_scores(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Contributor</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "      <th>Role</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google AI Blog: Permutation-Invariant Neural N...</td>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>[David Ha, Yujin Tang]</td>\n",
       "      <td>Posted by David Ha, Staff Research Scientist a...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/permutation-...</td>\n",
       "      <td>[Staff Research Scientist, Research Software E...</td>\n",
       "      <td>{'neg': 0.015, 'neu': 0.924, 'pos': 0.061, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google AI Blog: Making Better Future Predictio...</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>[Dave Epstein, Chen Sun]</td>\n",
       "      <td>Posted by Dave Epstein, Student Researcher and...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/making-bette...</td>\n",
       "      <td>[Student Researcher, Staff Research Scientist]</td>\n",
       "      <td>{'neg': 0.009, 'neu': 0.917, 'pos': 0.074, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google AI Blog: An Open Source Vibrotactile Ha...</td>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>[Artem Dementyev]</td>\n",
       "      <td>Posted by Artem Dementyev, Hardware Engineer, ...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/an-open-sour...</td>\n",
       "      <td>[Hardware Engineer]</td>\n",
       "      <td>{'neg': 0.02, 'neu': 0.903, 'pos': 0.076, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google AI Blog: MetNet-2: Deep Learning for 12...</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>[Nal Kalchbrenner, Lasse Espeholt]</td>\n",
       "      <td>Posted by Nal Kalchbrenner and Lasse Espeholt,...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/metnet-2-dee...</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.019, 'neu': 0.91, 'pos': 0.071, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google AI Blog: RLiable: Towards Reliable Eval...</td>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>[Rishabh Agarwal, Pablo Samuel Castro]</td>\n",
       "      <td>Posted by Rishabh Agarwal, Research Scientist ...</td>\n",
       "      <td>https://ai.googleblog.com/2021/11/rliable-towa...</td>\n",
       "      <td>[Research Scientist, Staff Software Engineer]</td>\n",
       "      <td>{'neg': 0.025, 'neu': 0.868, 'pos': 0.107, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Google AI Blog: First Robots</td>\n",
       "      <td>2006-03-22</td>\n",
       "      <td>[Sumit Agarwal, &amp; Michael Stoppelman]</td>\n",
       "      <td>Posted by  Sumit Agarwal, Maryam Kamvar, &amp; Mic...</td>\n",
       "      <td>https://ai.googleblog.com/2006/03/first-robots...</td>\n",
       "      <td>[Maryam Kamvar]</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.784, 'pos': 0.198, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Google AI Blog: See you at CHI</td>\n",
       "      <td>2006-04-23</td>\n",
       "      <td>[Rick Boardman]</td>\n",
       "      <td>Posted by Rick Boardman, User Experience Resea...</td>\n",
       "      <td>https://ai.googleblog.com/2006/04/see-you-at-c...</td>\n",
       "      <td>[User Experience Researcher]</td>\n",
       "      <td>{'neg': 0.01, 'neu': 0.862, 'pos': 0.128, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Google AI Blog: Our conference on automated te...</td>\n",
       "      <td>2006-04-27</td>\n",
       "      <td>[Allen Hutchison]</td>\n",
       "      <td>Posted by Allen Hutchison, Engineering Manager...</td>\n",
       "      <td>https://ai.googleblog.com/2006/04/our-conferen...</td>\n",
       "      <td>[Engineering Manager]</td>\n",
       "      <td>{'neg': 0.025, 'neu': 0.803, 'pos': 0.172, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Google AI Blog: Statistical machine translatio...</td>\n",
       "      <td>2006-04-28</td>\n",
       "      <td>[Franz Och]</td>\n",
       "      <td>Posted by Franz Och, Research ScientistBecause...</td>\n",
       "      <td>https://ai.googleblog.com/2006/04/statistical-...</td>\n",
       "      <td>[Research Scientist]</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.906, 'pos': 0.075, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Google AI Blog: Extra, Extra - Read All About ...</td>\n",
       "      <td>2006-06-02</td>\n",
       "      <td>[Joshua Bloch]</td>\n",
       "      <td>Posted by Joshua Bloch, Software EngineerI rem...</td>\n",
       "      <td>https://ai.googleblog.com/2006/06/extra-extra-...</td>\n",
       "      <td>[Software Engineer]</td>\n",
       "      <td>{'neg': 0.061, 'neu': 0.82, 'pos': 0.119, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title       Date  \\\n",
       "0     Google AI Blog: Permutation-Invariant Neural N... 2021-11-18   \n",
       "1     Google AI Blog: Making Better Future Predictio... 2021-11-11   \n",
       "2     Google AI Blog: An Open Source Vibrotactile Ha... 2021-11-12   \n",
       "3     Google AI Blog: MetNet-2: Deep Learning for 12... 2021-11-15   \n",
       "4     Google AI Blog: RLiable: Towards Reliable Eval... 2021-11-17   \n",
       "...                                                 ...        ...   \n",
       "1004                       Google AI Blog: First Robots 2006-03-22   \n",
       "1005                     Google AI Blog: See you at CHI 2006-04-23   \n",
       "1006  Google AI Blog: Our conference on automated te... 2006-04-27   \n",
       "1007  Google AI Blog: Statistical machine translatio... 2006-04-28   \n",
       "1008  Google AI Blog: Extra, Extra - Read All About ... 2006-06-02   \n",
       "\n",
       "                                 Contributor  \\\n",
       "0                     [David Ha, Yujin Tang]   \n",
       "1                   [Dave Epstein, Chen Sun]   \n",
       "2                          [Artem Dementyev]   \n",
       "3         [Nal Kalchbrenner, Lasse Espeholt]   \n",
       "4     [Rishabh Agarwal, Pablo Samuel Castro]   \n",
       "...                                      ...   \n",
       "1004   [Sumit Agarwal, & Michael Stoppelman]   \n",
       "1005                         [Rick Boardman]   \n",
       "1006                       [Allen Hutchison]   \n",
       "1007                             [Franz Och]   \n",
       "1008                          [Joshua Bloch]   \n",
       "\n",
       "                                                Content  \\\n",
       "0     Posted by David Ha, Staff Research Scientist a...   \n",
       "1     Posted by Dave Epstein, Student Researcher and...   \n",
       "2     Posted by Artem Dementyev, Hardware Engineer, ...   \n",
       "3     Posted by Nal Kalchbrenner and Lasse Espeholt,...   \n",
       "4     Posted by Rishabh Agarwal, Research Scientist ...   \n",
       "...                                                 ...   \n",
       "1004  Posted by  Sumit Agarwal, Maryam Kamvar, & Mic...   \n",
       "1005  Posted by Rick Boardman, User Experience Resea...   \n",
       "1006  Posted by Allen Hutchison, Engineering Manager...   \n",
       "1007  Posted by Franz Och, Research ScientistBecause...   \n",
       "1008  Posted by Joshua Bloch, Software EngineerI rem...   \n",
       "\n",
       "                                                   Link  \\\n",
       "0     https://ai.googleblog.com/2021/11/permutation-...   \n",
       "1     https://ai.googleblog.com/2021/11/making-bette...   \n",
       "2     https://ai.googleblog.com/2021/11/an-open-sour...   \n",
       "3     https://ai.googleblog.com/2021/11/metnet-2-dee...   \n",
       "4     https://ai.googleblog.com/2021/11/rliable-towa...   \n",
       "...                                                 ...   \n",
       "1004  https://ai.googleblog.com/2006/03/first-robots...   \n",
       "1005  https://ai.googleblog.com/2006/04/see-you-at-c...   \n",
       "1006  https://ai.googleblog.com/2006/04/our-conferen...   \n",
       "1007  https://ai.googleblog.com/2006/04/statistical-...   \n",
       "1008  https://ai.googleblog.com/2006/06/extra-extra-...   \n",
       "\n",
       "                                                   Role  \\\n",
       "0     [Staff Research Scientist, Research Software E...   \n",
       "1        [Student Researcher, Staff Research Scientist]   \n",
       "2                                   [Hardware Engineer]   \n",
       "3                                                         \n",
       "4         [Research Scientist, Staff Software Engineer]   \n",
       "...                                                 ...   \n",
       "1004                                    [Maryam Kamvar]   \n",
       "1005                       [User Experience Researcher]   \n",
       "1006                              [Engineering Manager]   \n",
       "1007                               [Research Scientist]   \n",
       "1008                                [Software Engineer]   \n",
       "\n",
       "                                                 Scores  \n",
       "0     {'neg': 0.015, 'neu': 0.924, 'pos': 0.061, 'co...  \n",
       "1     {'neg': 0.009, 'neu': 0.917, 'pos': 0.074, 'co...  \n",
       "2     {'neg': 0.02, 'neu': 0.903, 'pos': 0.076, 'com...  \n",
       "3     {'neg': 0.019, 'neu': 0.91, 'pos': 0.071, 'com...  \n",
       "4     {'neg': 0.025, 'neu': 0.868, 'pos': 0.107, 'co...  \n",
       "...                                                 ...  \n",
       "1004  {'neg': 0.018, 'neu': 0.784, 'pos': 0.198, 'co...  \n",
       "1005  {'neg': 0.01, 'neu': 0.862, 'pos': 0.128, 'com...  \n",
       "1006  {'neg': 0.025, 'neu': 0.803, 'pos': 0.172, 'co...  \n",
       "1007  {'neg': 0.018, 'neu': 0.906, 'pos': 0.075, 'co...  \n",
       "1008  {'neg': 0.061, 'neu': 0.82, 'pos': 0.119, 'com...  \n",
       "\n",
       "[1009 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Compound'] = df['Scores'].apply(lambda d: d['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Overall Score'] = df['Compound'].apply(lambda score: 'POS' if score >=0 else 'NEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Contributor</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "      <th>Role</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Overall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Google AI Blog: Demonstrating the Fundamentals...</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>[Jimmy Chen, Matt McEwen]</td>\n",
       "      <td>Posted by Jimmy Chen, Quantum Research Scienti...</td>\n",
       "      <td>https://ai.googleblog.com/2021/08/demonstratin...</td>\n",
       "      <td>[Quantum Research Scientist, Student Researcher]</td>\n",
       "      <td>{'neg': 0.117, 'neu': 0.81, 'pos': 0.073, 'com...</td>\n",
       "      <td>-0.9969</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Google AI Blog: Learning to Manipulate Deforma...</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>[Daniel Seita, Andy Zeng]</td>\n",
       "      <td>Posted by Daniel Seita, Research Intern and An...</td>\n",
       "      <td>https://ai.googleblog.com/2021/05/learning-to-...</td>\n",
       "      <td>[Research Intern, Research Scientist]</td>\n",
       "      <td>{'neg': 0.07, 'neu': 0.868, 'pos': 0.062, 'com...</td>\n",
       "      <td>-0.9216</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Google AI Blog: Do Wide and Deep Networks Lear...</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>[Thao Nguyen]</td>\n",
       "      <td>Posted by Thao Nguyen, AI Resident, Google Res...</td>\n",
       "      <td>https://ai.googleblog.com/2021/05/do-wide-and-...</td>\n",
       "      <td>[AI Resident]</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.896, 'pos': 0.042, 'co...</td>\n",
       "      <td>-0.9849</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Google AI Blog: Machine Learning-based Damage ...</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>[Joseph Xu, Pranav Khaitan]</td>\n",
       "      <td>Posted by Joseph Xu, Senior Software Engineer ...</td>\n",
       "      <td>https://ai.googleblog.com/2020/06/machine-lear...</td>\n",
       "      <td>[Senior Software Engineer, Engineering Lead]</td>\n",
       "      <td>{'neg': 0.134, 'neu': 0.755, 'pos': 0.111, 'co...</td>\n",
       "      <td>-0.9950</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Google AI Blog: Optimizing Multiple Loss Funct...</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>[Alexey Dosovitskiy]</td>\n",
       "      <td>Posted by Alexey Dosovitskiy, Research Scienti...</td>\n",
       "      <td>https://ai.googleblog.com/2020/04/optimizing-m...</td>\n",
       "      <td>[Research Scientist]</td>\n",
       "      <td>{'neg': 0.078, 'neu': 0.869, 'pos': 0.054, 'co...</td>\n",
       "      <td>-0.9821</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Google AI Blog: Bi-Tempered Logistic Loss for ...</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>[Ehsan Amid, Rohan Anil]</td>\n",
       "      <td>Posted by Ehsan Amid, Student Researcher and R...</td>\n",
       "      <td>https://ai.googleblog.com/2019/08/bi-tempered-...</td>\n",
       "      <td>[Student Researcher, Software Engineer]</td>\n",
       "      <td>{'neg': 0.127, 'neu': 0.793, 'pos': 0.08, 'com...</td>\n",
       "      <td>-0.9953</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Google AI Blog: Robust Neural Machine Translation</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>[Yong Cheng]</td>\n",
       "      <td>Posted by Yong Cheng, Software Engineer, Googl...</td>\n",
       "      <td>https://ai.googleblog.com/2019/07/robust-neura...</td>\n",
       "      <td>[Software Engineer]</td>\n",
       "      <td>{'neg': 0.116, 'neu': 0.78, 'pos': 0.104, 'com...</td>\n",
       "      <td>-0.9657</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Google AI Blog: Applying Deep Learning to Meta...</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>[Martin Stumpe, Craig Mermel]</td>\n",
       "      <td>Posted by Martin Stumpe, Technical Lead and Cr...</td>\n",
       "      <td>https://ai.googleblog.com/2018/10/applying-dee...</td>\n",
       "      <td>[Technical Lead, Product Manager]</td>\n",
       "      <td>{'neg': 0.11, 'neu': 0.787, 'pos': 0.104, 'com...</td>\n",
       "      <td>-0.9624</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Google AI Blog: Introducing the Unrestricted A...</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>[Tom B. Brown, Catherine Olsson]</td>\n",
       "      <td>Posted by Tom B. Brown and Catherine Olsson, R...</td>\n",
       "      <td>https://ai.googleblog.com/2018/09/introducing-...</td>\n",
       "      <td>Research Engineers</td>\n",
       "      <td>{'neg': 0.123, 'neu': 0.769, 'pos': 0.108, 'co...</td>\n",
       "      <td>-0.9592</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Google AI Blog: An Augmented Reality Microscop...</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>[Martin Stumpe, Craig Mermel]</td>\n",
       "      <td>Posted by Martin Stumpe, Technical Lead and Cr...</td>\n",
       "      <td>https://ai.googleblog.com/2018/04/an-augmented...</td>\n",
       "      <td>[Technical Lead, Product Manager]</td>\n",
       "      <td>{'neg': 0.058, 'neu': 0.874, 'pos': 0.068, 'co...</td>\n",
       "      <td>-0.1548</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Google AI Blog: Assessing Cardiovascular Risk ...</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>[Lily Peng MD PhD]</td>\n",
       "      <td>Posted by Lily Peng MD PhD, Product Manager, G...</td>\n",
       "      <td>https://ai.googleblog.com/2018/02/assessing-ca...</td>\n",
       "      <td>[Product Manager]</td>\n",
       "      <td>{'neg': 0.06, 'neu': 0.899, 'pos': 0.041, 'com...</td>\n",
       "      <td>-0.9305</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Google AI Blog: Keeping fake listings off Goog...</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>[Doug Grundman, ]</td>\n",
       "      <td>Posted by Doug Grundman, Maps Anti-Abuse, and ...</td>\n",
       "      <td>https://ai.googleblog.com/2017/04/keeping-fake...</td>\n",
       "      <td>[Maps Anti-Abuse, Kurt Thomas]</td>\n",
       "      <td>{'neg': 0.148, 'neu': 0.775, 'pos': 0.077, 'co...</td>\n",
       "      <td>-0.9963</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Google AI Blog: App Discovery with Google Play...</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>[Hsu-Chieh Lee, Software Engineers]</td>\n",
       "      <td>Posted by Hsu-Chieh Lee, Xing Chen, Software E...</td>\n",
       "      <td>https://ai.googleblog.com/2017/01/app-discover...</td>\n",
       "      <td>[Xing Chen, , Analyst]</td>\n",
       "      <td>{'neg': 0.118, 'neu': 0.777, 'pos': 0.105, 'co...</td>\n",
       "      <td>-0.9693</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Google AI Blog: A step closer to quantum compu...</td>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>[Julian Kelly, Rami Barends, , Austin Fowler]</td>\n",
       "      <td>Posted by Julian Kelly, Rami Barends, and Aust...</td>\n",
       "      <td>https://ai.googleblog.com/2015/03/a-step-close...</td>\n",
       "      <td>Quantum Electronics Engineers</td>\n",
       "      <td>{'neg': 0.122, 'neu': 0.776, 'pos': 0.102, 'co...</td>\n",
       "      <td>-0.9253</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Google AI Blog: Where does my data live?</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>[Daniel Ford]</td>\n",
       "      <td>Posted by Daniel Ford, Senior MathematicianHav...</td>\n",
       "      <td>https://ai.googleblog.com/2011/02/where-does-m...</td>\n",
       "      <td>[Senior Mathematician]</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.842, 'pos': 0.071, 'co...</td>\n",
       "      <td>-0.8594</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Google AI Blog: Clustering Related Queries Bas...</td>\n",
       "      <td>2010-10-13</td>\n",
       "      <td>[Jayant Madhavan, Alon Halevy]</td>\n",
       "      <td>Posted by Jayant Madhavan and Alon HalevyPeopl...</td>\n",
       "      <td>https://ai.googleblog.com/2010/10/clustering-r...</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.041, 'neu': 0.917, 'pos': 0.042, 'co...</td>\n",
       "      <td>-0.1116</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title       Date  \\\n",
       "44   Google AI Blog: Demonstrating the Fundamentals... 2021-08-11   \n",
       "76   Google AI Blog: Learning to Manipulate Deforma... 2021-05-14   \n",
       "85   Google AI Blog: Do Wide and Deep Networks Lear... 2021-05-04   \n",
       "187  Google AI Blog: Machine Learning-based Damage ... 2020-06-16   \n",
       "210  Google AI Blog: Optimizing Multiple Loss Funct... 2020-04-27   \n",
       "292  Google AI Blog: Bi-Tempered Logistic Loss for ... 2019-08-26   \n",
       "299  Google AI Blog: Robust Neural Machine Translation 2019-07-29   \n",
       "379  Google AI Blog: Applying Deep Learning to Meta... 2018-10-12   \n",
       "390  Google AI Blog: Introducing the Unrestricted A... 2018-09-13   \n",
       "424  Google AI Blog: An Augmented Reality Microscop... 2018-04-16   \n",
       "459  Google AI Blog: Assessing Cardiovascular Risk ... 2018-02-19   \n",
       "532  Google AI Blog: Keeping fake listings off Goog... 2017-04-06   \n",
       "552  Google AI Blog: App Discovery with Google Play... 2017-01-30   \n",
       "665  Google AI Blog: A step closer to quantum compu... 2015-03-04   \n",
       "871           Google AI Blog: Where does my data live? 2011-02-25   \n",
       "900  Google AI Blog: Clustering Related Queries Bas... 2010-10-13   \n",
       "\n",
       "                                       Contributor  \\\n",
       "44                       [Jimmy Chen, Matt McEwen]   \n",
       "76                       [Daniel Seita, Andy Zeng]   \n",
       "85                                   [Thao Nguyen]   \n",
       "187                    [Joseph Xu, Pranav Khaitan]   \n",
       "210                           [Alexey Dosovitskiy]   \n",
       "292                       [Ehsan Amid, Rohan Anil]   \n",
       "299                                   [Yong Cheng]   \n",
       "379                  [Martin Stumpe, Craig Mermel]   \n",
       "390               [Tom B. Brown, Catherine Olsson]   \n",
       "424                  [Martin Stumpe, Craig Mermel]   \n",
       "459                             [Lily Peng MD PhD]   \n",
       "532                              [Doug Grundman, ]   \n",
       "552            [Hsu-Chieh Lee, Software Engineers]   \n",
       "665  [Julian Kelly, Rami Barends, , Austin Fowler]   \n",
       "871                                  [Daniel Ford]   \n",
       "900                 [Jayant Madhavan, Alon Halevy]   \n",
       "\n",
       "                                               Content  \\\n",
       "44   Posted by Jimmy Chen, Quantum Research Scienti...   \n",
       "76   Posted by Daniel Seita, Research Intern and An...   \n",
       "85   Posted by Thao Nguyen, AI Resident, Google Res...   \n",
       "187  Posted by Joseph Xu, Senior Software Engineer ...   \n",
       "210  Posted by Alexey Dosovitskiy, Research Scienti...   \n",
       "292  Posted by Ehsan Amid, Student Researcher and R...   \n",
       "299  Posted by Yong Cheng, Software Engineer, Googl...   \n",
       "379  Posted by Martin Stumpe, Technical Lead and Cr...   \n",
       "390  Posted by Tom B. Brown and Catherine Olsson, R...   \n",
       "424  Posted by Martin Stumpe, Technical Lead and Cr...   \n",
       "459  Posted by Lily Peng MD PhD, Product Manager, G...   \n",
       "532  Posted by Doug Grundman, Maps Anti-Abuse, and ...   \n",
       "552  Posted by Hsu-Chieh Lee, Xing Chen, Software E...   \n",
       "665  Posted by Julian Kelly, Rami Barends, and Aust...   \n",
       "871  Posted by Daniel Ford, Senior MathematicianHav...   \n",
       "900  Posted by Jayant Madhavan and Alon HalevyPeopl...   \n",
       "\n",
       "                                                  Link  \\\n",
       "44   https://ai.googleblog.com/2021/08/demonstratin...   \n",
       "76   https://ai.googleblog.com/2021/05/learning-to-...   \n",
       "85   https://ai.googleblog.com/2021/05/do-wide-and-...   \n",
       "187  https://ai.googleblog.com/2020/06/machine-lear...   \n",
       "210  https://ai.googleblog.com/2020/04/optimizing-m...   \n",
       "292  https://ai.googleblog.com/2019/08/bi-tempered-...   \n",
       "299  https://ai.googleblog.com/2019/07/robust-neura...   \n",
       "379  https://ai.googleblog.com/2018/10/applying-dee...   \n",
       "390  https://ai.googleblog.com/2018/09/introducing-...   \n",
       "424  https://ai.googleblog.com/2018/04/an-augmented...   \n",
       "459  https://ai.googleblog.com/2018/02/assessing-ca...   \n",
       "532  https://ai.googleblog.com/2017/04/keeping-fake...   \n",
       "552  https://ai.googleblog.com/2017/01/app-discover...   \n",
       "665  https://ai.googleblog.com/2015/03/a-step-close...   \n",
       "871  https://ai.googleblog.com/2011/02/where-does-m...   \n",
       "900  https://ai.googleblog.com/2010/10/clustering-r...   \n",
       "\n",
       "                                                 Role  \\\n",
       "44   [Quantum Research Scientist, Student Researcher]   \n",
       "76              [Research Intern, Research Scientist]   \n",
       "85                                      [AI Resident]   \n",
       "187      [Senior Software Engineer, Engineering Lead]   \n",
       "210                              [Research Scientist]   \n",
       "292           [Student Researcher, Software Engineer]   \n",
       "299                               [Software Engineer]   \n",
       "379                 [Technical Lead, Product Manager]   \n",
       "390                                Research Engineers   \n",
       "424                 [Technical Lead, Product Manager]   \n",
       "459                                 [Product Manager]   \n",
       "532                    [Maps Anti-Abuse, Kurt Thomas]   \n",
       "552                            [Xing Chen, , Analyst]   \n",
       "665                     Quantum Electronics Engineers   \n",
       "871                            [Senior Mathematician]   \n",
       "900                                                     \n",
       "\n",
       "                                                Scores  Compound Overall Score  \n",
       "44   {'neg': 0.117, 'neu': 0.81, 'pos': 0.073, 'com...   -0.9969           NEG  \n",
       "76   {'neg': 0.07, 'neu': 0.868, 'pos': 0.062, 'com...   -0.9216           NEG  \n",
       "85   {'neg': 0.062, 'neu': 0.896, 'pos': 0.042, 'co...   -0.9849           NEG  \n",
       "187  {'neg': 0.134, 'neu': 0.755, 'pos': 0.111, 'co...   -0.9950           NEG  \n",
       "210  {'neg': 0.078, 'neu': 0.869, 'pos': 0.054, 'co...   -0.9821           NEG  \n",
       "292  {'neg': 0.127, 'neu': 0.793, 'pos': 0.08, 'com...   -0.9953           NEG  \n",
       "299  {'neg': 0.116, 'neu': 0.78, 'pos': 0.104, 'com...   -0.9657           NEG  \n",
       "379  {'neg': 0.11, 'neu': 0.787, 'pos': 0.104, 'com...   -0.9624           NEG  \n",
       "390  {'neg': 0.123, 'neu': 0.769, 'pos': 0.108, 'co...   -0.9592           NEG  \n",
       "424  {'neg': 0.058, 'neu': 0.874, 'pos': 0.068, 'co...   -0.1548           NEG  \n",
       "459  {'neg': 0.06, 'neu': 0.899, 'pos': 0.041, 'com...   -0.9305           NEG  \n",
       "532  {'neg': 0.148, 'neu': 0.775, 'pos': 0.077, 'co...   -0.9963           NEG  \n",
       "552  {'neg': 0.118, 'neu': 0.777, 'pos': 0.105, 'co...   -0.9693           NEG  \n",
       "665  {'neg': 0.122, 'neu': 0.776, 'pos': 0.102, 'co...   -0.9253           NEG  \n",
       "871  {'neg': 0.088, 'neu': 0.842, 'pos': 0.071, 'co...   -0.8594           NEG  \n",
       "900  {'neg': 0.041, 'neu': 0.917, 'pos': 0.042, 'co...   -0.1116           NEG  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Overall Score'] == 'NEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=.9, min_df=.1, stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1009x590 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 115286 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvmoraes\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names()) #Mesmo tamanho do dtm, ou seja, são mil e poucas dimensoes (documentos) por 590 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conference'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LDA.components_) #Retorna o numero de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([507, 169, 279, 222, 524, 353, 422, 113, 350,  53, 301, 527, 223,\n",
       "        45, 538, 144, 171, 546, 562, 580, 184, 533, 108, 496, 554, 125,\n",
       "       358, 430, 203, 499, 172, 264, 490, 486, 326, 468, 187,  69, 569,\n",
       "        52, 417, 150, 406, 469,  41, 374, 489, 403, 536, 269, 581, 514,\n",
       "       364, 148, 337,  75, 266, 457, 318, 412, 361, 272, 140, 453, 319,\n",
       "       183, 428, 283, 563, 446, 559, 320, 134,  93, 239, 515, 488, 188,\n",
       "       305,  95, 583, 306, 577,  60,  96, 377, 162, 296, 418, 473, 190,\n",
       "       139, 315,  94, 416, 547, 541,  23,  99, 164, 154, 103, 286, 120,\n",
       "       414, 173, 304, 383, 481, 119, 170, 271, 349, 566, 191, 167,  74,\n",
       "       525, 467, 299,  91, 578,  10, 384, 574,  85, 576, 357,  62, 366,\n",
       "       390, 189, 400, 336, 152, 158, 205, 309, 352, 226, 386, 260, 516,\n",
       "       256, 558, 439, 497, 314, 265, 186, 224, 308, 229, 105, 396, 137,\n",
       "        35, 181, 401, 461, 330, 407, 208,  59, 548, 419, 431, 550, 505,\n",
       "       584, 579, 402, 460, 101, 323, 388, 117, 136, 435,  13, 259, 274,\n",
       "        79, 413, 575, 362, 587, 409,  16, 432, 155, 452,  31, 115,  54,\n",
       "       379, 100,  47, 254, 429, 573, 312, 270, 588, 128,  30, 421,  70,\n",
       "       243, 228, 195, 116, 360, 539, 317, 206, 459,  65, 151, 441, 255,\n",
       "       282, 227,  27,  84, 500, 335, 455, 257,  40, 397, 327, 263, 503,\n",
       "       510,   2, 238, 502, 343, 520, 124, 553,  24, 522,  33, 230,   4,\n",
       "       365, 174, 200, 197, 303,   5,   3, 168, 454, 540, 381, 313, 129,\n",
       "       474, 532,  92,  25, 498,  20, 398,  29, 211, 567, 287,  86, 159,\n",
       "        44, 491,  26, 111, 114, 371,  56, 180, 405,  80, 131, 410,  68,\n",
       "       325, 534, 513,  61, 176, 493, 127, 235, 298, 311, 221, 445, 472,\n",
       "       436, 464, 385, 130, 476, 408, 391, 153,  82, 217, 363, 249, 135,\n",
       "       549, 138, 285, 447, 212, 376, 521, 273,  97, 110, 232, 495, 399,\n",
       "       425,   7, 394, 537, 106, 284,   0, 143, 523, 297,  46, 448, 253,\n",
       "       107, 166,   8,  50, 247, 142, 324, 240, 175,  88,  15,  48, 300,\n",
       "        14, 560, 564, 442, 198, 220, 367, 261, 344, 278, 294, 147, 163,\n",
       "        72, 382,   9,  19, 214, 440, 485, 356,  39,  22,  63, 395, 484,\n",
       "       321, 420, 589,  64, 104,  43, 380, 267, 219, 508,  28, 216, 157,\n",
       "        21,  34, 225, 509, 160, 551, 248, 234, 427, 373, 346, 316, 213,\n",
       "       411, 156, 504, 378, 268, 463, 209, 233, 218, 102, 519, 487, 328,\n",
       "       483, 471, 392, 462, 204,   1, 389, 477, 372,  67, 492, 531, 192,\n",
       "       185,  89, 210, 535, 424, 434, 215, 512, 557, 231, 250,  17, 458,\n",
       "       565, 332,   6, 199, 112, 333, 196, 207, 475,  90, 302, 146,  83,\n",
       "       570, 345,  57, 246, 182, 258,  36, 451, 145, 291,  81, 480, 236,\n",
       "        73, 355, 478, 281, 482, 444, 359,  18, 369, 450, 245,  76,  66,\n",
       "       506, 585,  12, 118, 354, 244, 132, 433, 479, 404,  87, 161, 251,\n",
       "        37, 202, 494, 375, 149, 368, 526, 109, 339, 295,  32, 340, 586,\n",
       "       393,  38, 342, 334, 310, 252, 555,  49, 415, 582, 165, 338, 292,\n",
       "       177, 552, 529, 542,  55, 289, 528, 530, 288,  11, 423, 322,  58,\n",
       "       178,  51, 179, 568, 293, 545, 341, 437, 141, 193, 556, 351, 501,\n",
       "       470, 449, 275, 262, 276, 126, 307, 194, 370, 201, 561, 426, 456,\n",
       "        77, 237, 443,  42, 466, 280, 465,  71, 121, 543,  98, 517, 387,\n",
       "       438,  78, 518, 277, 511, 123, 133, 329, 572, 331, 571, 348, 290,\n",
       "       544, 347, 122, 242, 241], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_topic.argsort() #retorna um array com o numero dos indices dos valores sorteados em ordem do menor pro maior\n",
    "\n",
    "#ex: [10, 200, 1] retornaria [2, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual\n",
      "models\n",
      "vision\n",
      "objects\n",
      "learning\n",
      "training\n",
      "object\n",
      "dataset\n",
      "images\n",
      "image\n"
     ]
    }
   ],
   "source": [
    "for index in top_ten:\n",
    "    print(cv.get_feature_names_out()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open(\n",
    "    'df.txt', 'w'\n",
    ")\n",
    "sys.stdout = f\n",
    "\n",
    "\n",
    "for index, topic in enumerate(LDA.components_):\n",
    "    dataframe = pd.DataFrame(columns=[f'THE TOP 15 WORDS FOR TOPIC #{index}'], data=[cv.get_feature_names_out()[index] for index in topic.argsort()[-15:]])\n",
    "    print(dataframe)\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #0</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #1</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #2</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #3</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #4</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #5</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #6</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #7</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #8</th>\n",
       "      <th>THE TOP 15 WORDS FOR TOPIC #9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0                         labels</td>\n",
       "      <td>0                       accuracy</td>\n",
       "      <td>0                        machine</td>\n",
       "      <td>0                           used</td>\n",
       "      <td>0                           work</td>\n",
       "      <td>0                  reinforcement</td>\n",
       "      <td>0                      different</td>\n",
       "      <td>0                          cloud</td>\n",
       "      <td>0                           page</td>\n",
       "      <td>0                     technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1                     supervised</td>\n",
       "      <td>1                            new</td>\n",
       "      <td>1                        systems</td>\n",
       "      <td>1                           user</td>\n",
       "      <td>1                          based</td>\n",
       "      <td>1                     algorithms</td>\n",
       "      <td>1                           left</td>\n",
       "      <td>1                    information</td>\n",
       "      <td>1                          based</td>\n",
       "      <td>1                         course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2                       datasets</td>\n",
       "      <td>2                           time</td>\n",
       "      <td>2                        example</td>\n",
       "      <td>2                         mobile</td>\n",
       "      <td>2                    performance</td>\n",
       "      <td>2                          david</td>\n",
       "      <td>2                          layer</td>\n",
       "      <td>2                             ve</td>\n",
       "      <td>2                       datasets</td>\n",
       "      <td>2                           work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3                      detection</td>\n",
       "      <td>3                          state</td>\n",
       "      <td>3                           data</td>\n",
       "      <td>3                         videos</td>\n",
       "      <td>3                      different</td>\n",
       "      <td>3                   optimization</td>\n",
       "      <td>3                          using</td>\n",
       "      <td>3                           help</td>\n",
       "      <td>3                          large</td>\n",
       "      <td>3                         online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4                          model</td>\n",
       "      <td>4                         neural</td>\n",
       "      <td>4                        natural</td>\n",
       "      <td>4                          input</td>\n",
       "      <td>4                             ml</td>\n",
       "      <td>4                         models</td>\n",
       "      <td>4                           like</td>\n",
       "      <td>4                           time</td>\n",
       "      <td>4                      knowledge</td>\n",
       "      <td>4                        faculty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5                         visual</td>\n",
       "      <td>5                   architecture</td>\n",
       "      <td>5                         speech</td>\n",
       "      <td>5                        quality</td>\n",
       "      <td>5                           used</td>\n",
       "      <td>5                             li</td>\n",
       "      <td>5                           high</td>\n",
       "      <td>5                          world</td>\n",
       "      <td>5                    information</td>\n",
       "      <td>5                        systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6                         models</td>\n",
       "      <td>6                          using</td>\n",
       "      <td>6                        english</td>\n",
       "      <td>6                         device</td>\n",
       "      <td>6                        example</td>\n",
       "      <td>6                       networks</td>\n",
       "      <td>6                        example</td>\n",
       "      <td>6                            use</td>\n",
       "      <td>6                       research</td>\n",
       "      <td>6                           year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7                         vision</td>\n",
       "      <td>7                       learning</td>\n",
       "      <td>7                         models</td>\n",
       "      <td>7                          pixel</td>\n",
       "      <td>7                           real</td>\n",
       "      <td>7                           chen</td>\n",
       "      <td>7                         layers</td>\n",
       "      <td>7                           make</td>\n",
       "      <td>7                          video</td>\n",
       "      <td>7                            new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8                        objects</td>\n",
       "      <td>8                           task</td>\n",
       "      <td>8                          model</td>\n",
       "      <td>8                          using</td>\n",
       "      <td>8                          using</td>\n",
       "      <td>8                       research</td>\n",
       "      <td>8                          right</td>\n",
       "      <td>8                           like</td>\n",
       "      <td>8                     algorithms</td>\n",
       "      <td>8                      computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9                       learning</td>\n",
       "      <td>9                        network</td>\n",
       "      <td>9                           word</td>\n",
       "      <td>9                           time</td>\n",
       "      <td>9                        dataset</td>\n",
       "      <td>9                     tensorflow</td>\n",
       "      <td>9                     resolution</td>\n",
       "      <td>9                         people</td>\n",
       "      <td>9                        dataset</td>\n",
       "      <td>9                        program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10                      training</td>\n",
       "      <td>10                   performance</td>\n",
       "      <td>10                         words</td>\n",
       "      <td>10                         audio</td>\n",
       "      <td>10                        models</td>\n",
       "      <td>10                          deep</td>\n",
       "      <td>10                        neural</td>\n",
       "      <td>10                         users</td>\n",
       "      <td>10                     algorithm</td>\n",
       "      <td>10                       science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11                        object</td>\n",
       "      <td>11                         tasks</td>\n",
       "      <td>11                   translation</td>\n",
       "      <td>11                        camera</td>\n",
       "      <td>11                      learning</td>\n",
       "      <td>11                       include</td>\n",
       "      <td>11                      networks</td>\n",
       "      <td>11                          open</td>\n",
       "      <td>11                         paper</td>\n",
       "      <td>11                      students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12                       dataset</td>\n",
       "      <td>12                      training</td>\n",
       "      <td>12                     languages</td>\n",
       "      <td>12                         video</td>\n",
       "      <td>12                      training</td>\n",
       "      <td>12                        neural</td>\n",
       "      <td>12                        images</td>\n",
       "      <td>12                           new</td>\n",
       "      <td>12                           web</td>\n",
       "      <td>12                      computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13                        images</td>\n",
       "      <td>13                        models</td>\n",
       "      <td>13                          text</td>\n",
       "      <td>13                        speech</td>\n",
       "      <td>13                         model</td>\n",
       "      <td>13                       machine</td>\n",
       "      <td>13                       network</td>\n",
       "      <td>13                      research</td>\n",
       "      <td>13                         graph</td>\n",
       "      <td>13                    university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14                         image</td>\n",
       "      <td>14                         model</td>\n",
       "      <td>14                      language</td>\n",
       "      <td>14                         model</td>\n",
       "      <td>14                          data</td>\n",
       "      <td>14                      learning</td>\n",
       "      <td>14                         image</td>\n",
       "      <td>14                          data</td>\n",
       "      <td>14                        search</td>\n",
       "      <td>14                      research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      THE TOP 15 WORDS FOR TOPIC #0     THE TOP 15 WORDS FOR TOPIC #1  \\\n",
       "0   0                         labels  0                       accuracy   \n",
       "1   1                     supervised  1                            new   \n",
       "2   2                       datasets  2                           time   \n",
       "3   3                      detection  3                          state   \n",
       "4   4                          model  4                         neural   \n",
       "5   5                         visual  5                   architecture   \n",
       "6   6                         models  6                          using   \n",
       "7   7                         vision  7                       learning   \n",
       "8   8                        objects  8                           task   \n",
       "9   9                       learning  9                        network   \n",
       "10  10                      training  10                   performance   \n",
       "11  11                        object  11                         tasks   \n",
       "12  12                       dataset  12                      training   \n",
       "13  13                        images  13                        models   \n",
       "14  14                         image  14                         model   \n",
       "\n",
       "0      THE TOP 15 WORDS FOR TOPIC #2     THE TOP 15 WORDS FOR TOPIC #3  \\\n",
       "0   0                        machine  0                           used   \n",
       "1   1                        systems  1                           user   \n",
       "2   2                        example  2                         mobile   \n",
       "3   3                           data  3                         videos   \n",
       "4   4                        natural  4                          input   \n",
       "5   5                         speech  5                        quality   \n",
       "6   6                        english  6                         device   \n",
       "7   7                         models  7                          pixel   \n",
       "8   8                          model  8                          using   \n",
       "9   9                           word  9                           time   \n",
       "10  10                         words  10                         audio   \n",
       "11  11                   translation  11                        camera   \n",
       "12  12                     languages  12                         video   \n",
       "13  13                          text  13                        speech   \n",
       "14  14                      language  14                         model   \n",
       "\n",
       "0      THE TOP 15 WORDS FOR TOPIC #4     THE TOP 15 WORDS FOR TOPIC #5  \\\n",
       "0   0                           work  0                  reinforcement   \n",
       "1   1                          based  1                     algorithms   \n",
       "2   2                    performance  2                          david   \n",
       "3   3                      different  3                   optimization   \n",
       "4   4                             ml  4                         models   \n",
       "5   5                           used  5                             li   \n",
       "6   6                        example  6                       networks   \n",
       "7   7                           real  7                           chen   \n",
       "8   8                          using  8                       research   \n",
       "9   9                        dataset  9                     tensorflow   \n",
       "10  10                        models  10                          deep   \n",
       "11  11                      learning  11                       include   \n",
       "12  12                      training  12                        neural   \n",
       "13  13                         model  13                       machine   \n",
       "14  14                          data  14                      learning   \n",
       "\n",
       "0      THE TOP 15 WORDS FOR TOPIC #6     THE TOP 15 WORDS FOR TOPIC #7  \\\n",
       "0   0                      different  0                          cloud   \n",
       "1   1                           left  1                    information   \n",
       "2   2                          layer  2                             ve   \n",
       "3   3                          using  3                           help   \n",
       "4   4                           like  4                           time   \n",
       "5   5                           high  5                          world   \n",
       "6   6                        example  6                            use   \n",
       "7   7                         layers  7                           make   \n",
       "8   8                          right  8                           like   \n",
       "9   9                     resolution  9                         people   \n",
       "10  10                        neural  10                         users   \n",
       "11  11                      networks  11                          open   \n",
       "12  12                        images  12                           new   \n",
       "13  13                       network  13                      research   \n",
       "14  14                         image  14                          data   \n",
       "\n",
       "0      THE TOP 15 WORDS FOR TOPIC #8     THE TOP 15 WORDS FOR TOPIC #9  \n",
       "0   0                           page  0                     technology  \n",
       "1   1                          based  1                         course  \n",
       "2   2                       datasets  2                           work  \n",
       "3   3                          large  3                         online  \n",
       "4   4                      knowledge  4                        faculty  \n",
       "5   5                    information  5                        systems  \n",
       "6   6                       research  6                           year  \n",
       "7   7                          video  7                            new  \n",
       "8   8                     algorithms  8                      computing  \n",
       "9   9                        dataset  9                        program  \n",
       "10  10                     algorithm  10                       science  \n",
       "11  11                         paper  11                      students  \n",
       "12  12                           web  12                      computer  \n",
       "13  13                         graph  13                    university  \n",
       "14  14                        search  14                      research  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_table('df.txt', header=None)\n",
    "import numpy as np\n",
    "arr = np.array(df2)\n",
    "dataframe = pd.DataFrame(arr.reshape((10, 16))).T\n",
    "headers = dataframe.iloc[0]\n",
    "new_df = pd.DataFrame(data=dataframe.values[1:], columns=headers)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic\n",
       "7    189\n",
       "9    150\n",
       "4    130\n",
       "1    125\n",
       "3     95\n",
       "2     78\n",
       "5     69\n",
       "0     69\n",
       "8     64\n",
       "6     40"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85ea59b576b4d42e5b007ccfc29f7533bd412890d47039184691991a9b14feb4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
